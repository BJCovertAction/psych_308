---
title: "PSYCH308D - Data Cleaning Warmm Up"
author: "Nahrie Norvell & Brady C. Jackson"
date: "2025/04/17"

# Write document output to HTML, Word, and PDF output types with a Table of
# contents included.
output: 
  html_document:
    toc: true
  word_document:
    toc: true
#  pdf_document:
#    toc: true
#    latex_engine: xelatex

# This option here enables output to both HTML and PDF formats
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---ONLY WRITE CODE BELOW THIS LINE---

# Library Loading

Load all requisite libraries here.

```{r package_loading, message=FALSE, warning=FALSE}
# Load packages. Set messages and warnings to FALSE so I don't have to see the
# masking messages in the output.
library(jmv)       # for descriptive
library(ggplot2)
library(dplyr)
library(corrplot)    # For fancy covariance matrix plots
library(apaTables)   # For Word formatted tables
library(car)         # for ncvTest (Breusch Pagan)
library(tidyverse)
library(jmv)       # for descriptive
library(ggplot2)
library(dplyr)
library(psych)
library(corrplot)    # For fancy covariance matrix plots
library(car)         # for ncvTest (Breusch Pagan)
library(stringr)     # for sub_str operations
library(Hmisc)       # for fun.dat substitution
library(see)         # for outliers analysis 
library(magrittr)
library(foreign)
library(broom)
library(robmed)
library(mediation)   # For mediation analysis
library(multilevel)
library(GGally)
library(lsr)
library(car)
library(mvnTest)     # Multivariate Normality
library(lm.beta)
library(lavaan)      # Structural Equation Modeling
library(haven)
library(foreign)
library(parallel)
# library(AER)

library(dplyr)
library(janitor)
library(naniar)
library(mice)

```

# Metadata

This section of code is to setup some general variables that we'll use throughout the code (e.g. figure colors, etc)

```{r metadata}
# First we'll defines some meta-data to use in all of our plots so they're nice and clean
font_color = "#4F81BD"
grid_color_major = "#9BB7D9"
grid_color_minor = "#C8D7EA"
back_color = "gray95"
rb_colmap = colorRampPalette( c("firebrick", "grey86", "dodgerblue3") )(200)

# I'm going to try to save off my preferred ggplot theme combinations as a unqiue theme object that I can just reference
# later in the code....totally unclear if ggplot works this way....
my_gg_theme = theme_minimal() +
              theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
                     axis.title.x = element_text(color = font_color),
                     axis.title.y = element_text(color = font_color),
                     axis.text.x = element_text(color = font_color),
                     axis.text.y = element_text(color = font_color),
                     legend.title = element_text(color = font_color),
                     legend.text = element_text(color = font_color),
                     panel.grid.minor = element_line(color = grid_color_minor),
                     panel.grid.major = element_line(color = grid_color_major),
                     panel.background = element_rect(fill = back_color, color = font_color)
                   )

# Setup filepath metadata
working_dir = fullpath(c(here, "Lectures and Demos", "data_cleaning", "warm_up"))

```

# Summary of What to Do

 - Delete names and e-mails, location, english,
 - Delete header rows
 - No Need to Coalesce ... no survey split as far as we can tell
 - Use informed consent to throw out non-consensual data
 - Use attention check to throw out inattentive data
 - Map satisfaction scales to numerics
 - Relocate as we go. Start w/ pushing attention check and non-consensual columns to the back


# Load Uncleaned Data

Here we load the dataframe from the CSV file from the excel edited downloaded data.


```{r load_raw_data}

# Filename and location of raw data.
raw_dat_filename <- "cleaning practice data 308d_sp25.csv"
raw_dat_file <-fullpath(c(working_dir, raw_dat_filename))

# Load the assignment data from CSV
raw_dat = read.csv(raw_dat_file)

# Rename columns to lower because why not
colnames(raw_dat) <- tolower( colnames(raw_dat) )

# Ensure that the numbers of each subject in the study are unique to prevent any duplicate data
# if the size of the unique-entries only is the same as the whole vector then there are no duplicate subjects
# NOTE: This fails if the colname of the subject ID is input wrong (e.g. if the subject ID is not named "participant"
#       in the dataframe. So check that the colname exists before blindly believing)
test_unique = (length(unique(raw_dat$participant)) == length(raw_dat$participant))
if(!test_unique){
    print("WARNING: There are duplicate data entries in the raw data")
}else{
    print("No duplicate entries detected in raw data")
}

# Save off all continuous variable names
# cont_names <- c('age', colnames(raw_dat[5:21]))

```


# Descriptive Statistics - Raw Data

Get an initial hack on the descriptives before we clean the data.

```{r descriptive_stats_raw}

# # We'll need to check both univariate normality and multi-variate normality.
# #    NOTE: We need to use the vars = cont_names[] syntax with [] included to access the contents of
# #          cont_names. Otherwise jamovi recognizes it as a character array object and it craps out.
# raw_descr = jmv::descriptives( raw_dat,
#                                 vars = cont_names[],
#                                 hist = TRUE,
#                                 dens = TRUE,
#                                 sd = TRUE,
#                                 variance = TRUE,
#                                 se = TRUE,
#                                 skew = TRUE,
#                                 kurt = TRUE,
#                                 missing = TRUE
#                               )
# 
# # Print descriptives output to Knitted Rmd file
# print(raw_descr)
# 
# # Dump raw descriptives Rmd output to a text file
# # Open the raw descriptives output file.
# raw_descr_out_filename <- "raw_dat_descriptives.txt"
# raw_descr_out_file <- fullpath( c( working_dir, raw_descr_out_filename) ) 
# raw_decr_out_stream <- file(raw_descr_out_file, open = "wt")
# 
# # Dump the formated text portion of the descriptives object.
# writeLines( "RAW DATA", raw_decr_out_stream )
# writeLines( capture.output( print( raw_descr$descriptives ) ), raw_decr_out_stream )
# 
# # Close the raw descriptives file stream
# close(raw_decr_out_stream)

```

# Clean Data

## Header Removal

```{r head_removal }
#remove row 1 and 2 which include the variable description and the qualtrics question number
dat2 <- raw_dat %>% slice(-(1:2))

# Move finished to the back so we don't nuke it
dat2 <- dat2 %>% relocate(finished, .after=last_col())
```

## Column Removal - Stuff we Don't Need

```{r col_removal }
#remove automatic qualtrics columns that are not of interest (Start, end, status, ip, progress, duration, finish, rec.date, responseid, lastname, firstname,email, ex.refernce, latitude, longitude,dischannel, language)

# "Finished" was kept for later processing logic. Moved to back. Qualtrics junk data is in columns 1:16 now.
dat3 <- dat2 %>% dplyr::select(c(17:44))

# Delete "x" from dat3
drop_cols = c('x')
keep_cols = setdiff(colnames(dat3), drop_cols)
dat4 = dat3[ , keep_cols]
```

## Throw Out Non-Attentive Data
```{r, no_attention}

#change attention check to numeric - not needed
dat4$attention.check <- as.numeric(dat4$attention.check)

#filter out people whose attention check answer was not 40 (4x10 = 40)
dat5 <- dat4 %>% dplyr::filter(attention.check =='40' | 
                               attention.check == 'forty' | 
                               attention.check=="Forty" | 
                               attention.check=="FORTY" )

#resulting sample size = 1812 (removed 22 participants who failed the attention check). Original size was 1834

#remove the attention check column
dat6 <- dat5 %>% dplyr::select(-c("attention.check"))

```


## Throw out Non-Consensual Data
```{r no_consent}
#change attention check to numeric - not needed
dat6$informed.consent <- as.numeric(dat6$informed.consent)

#filter out people whose attention check answer was not 40 (4x10 = 40)
dat7 <- dat6 %>% dplyr::filter(informed.consent =='1')

#result in no data reduction

#remove the attention check column
dat7 <- dat7 %>% dplyr::select(-c("informed.consent"))

```

