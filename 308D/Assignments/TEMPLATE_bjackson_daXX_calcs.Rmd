---
title: "PSYCH308D - Data Analysis __ (DA__)"
author: "Brady C. Jackson"
date: "2025/__/__"

# Write document output to HTML, Word, and PDF output types with a Table of
# contents included.
output: 
  html_document:
    toc: true
  word_document:
    toc: true
  pdf_document:
    toc: true
    latex_engine: xelatex

# This option here enables output to both HTML and PDF formats
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

## Prompt
Input Prompt Here

## Variables 

Input Variable Table HERE

| Variable | Type | Description |
|:-----|:---|:------------------|
| `Var1` | numeric | Descriptive sentence 1 |
| `Var2` | bool    | Descriptive sentence 2 |
| `Var3` | binary  | Descriptive sentence 3 |

## Assignment

### Part 1

Run the appropriate assumptions and analyses and report your findings in an APA format results section.   
Include tables and figures as necessary. 

### Part 2

*Respond to the following questions.*

1. Question 1
2. Question 2

---ONLY WRITE CODE BELOW THIS LINE---

## Code

Load all requisite libraries here.

```{r package_loading, message=FALSE, warning=FALSE}
# Load packages. Set messages and warnings to FALSE so I don't have to see the
# masking messages in the output.
library(jmv)       # for descriptive
library(ggplot2)
library(dplyr)
library(corrplot)    # For fancy covariance matrix plots
library(apaTables)   # For Word formatted tables
library(car)         # for ncvTest (Breusch Pagan)
library(tidyverse)
library(jmv)       # for descriptive
library(ggplot2)
library(dplyr)
library(psych)
library(corrplot)    # For fancy covariance matrix plots
library(car)         # for ncvTest (Breusch Pagan)
library(stringr)     # for sub_str operations
library(Hmisc)       # for fun.dat substitution
library(see)         # for outliers analysis 
library(magrittr)
library(foreign)
library(broom)
library(robmed)
library(mediation)   # For mediation analysis
library(multilevel)
library(GGally)
library(lsr)
library(car)
library(mvnTest)     # Multivariate Normality
library(lm.beta)
library(lavaan)      # Structural Equation Modeling
library(haven)
library(foreign)
# library(AER)

```

### Metadata

This section of code is to setup some general variables that we'll use throughout the code (e.g. figure colors, etc)

```{r metadata}
# First we'll defines some meta-data to use in all of our plots so they're nice and clean
font_color = "#4F81BD"
grid_color_major = "#9BB7D9"
grid_color_minor = "#C8D7EA"
back_color = "gray95"
rb_colmap = colorRampPalette( c("firebrick", "grey86", "dodgerblue3") )(200)

# I'm going to try to save off my preferred ggplot theme combinations as a unqiue theme object that I can just reference
# later in the code....totally unclear if ggplot works this way....
my_gg_theme = theme_minimal() +
              theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
                     axis.title.x = element_text(color = font_color),
                     axis.title.y = element_text(color = font_color),
                     axis.text.x = element_text(color = font_color),
                     axis.text.y = element_text(color = font_color),
                     legend.title = element_text(color = font_color),
                     legend.text = element_text(color = font_color),
                     panel.grid.minor = element_line(color = grid_color_minor),
                     panel.grid.major = element_line(color = grid_color_major),
                     panel.background = element_rect(fill = back_color, color = font_color)
                   )

```

### Load and View data

Here we load the dataframe from the CSV file provided for the assignment, and we 


```{r load_raw_data}
# 
# # Load the assignment data from CSV
# raw_dat = read.csv("./308D.DA1 Mediation.Data.csv")
# 
# # Rename columns to lower because why not
# colnames(raw_dat) <- tolower( colnames(raw_dat) )
# 
# # View data
# # glimpse(breaks_raw_dat)
# 
# # Ensure that the numbers of each subject in the study are unique to prevent any duplicate data
# # if the size of the unique-entries only is the same as the whole vector then there are no duplicate subjects
# # NOTE: This fails if the colname of the subject ID is input wrong (e.g. if the subject ID is not named "participant"
# #       in the dataframe. So check that the colname exists before blindly believing)
# test_unique = (length(unique(raw_dat$participant)) == length(raw_dat$participant))
# if(!test_unique){
#     print("WARNING: There are duplicate data entries in the raw data")
# }else{
#     print("No duplicate entries detected in raw data")
# }

```

### Add Centered and Standardized Data

It is often useful to have the centered data and standardized data in addition to the uncentered data.
So we add that here manually.

For the purposes of mediation models, we need manually defined models that rely on standardized data (centered and   
scaled by standard deviation). We could compute this manually after extracting the mean and SD from the descriptives   
dataframe, but the "scale" function builds this capability automagically in R so we just use it here.

```{r center_data}

# # Center all continuous data as defined by the cont_names array below
# cont_names = c('ja', 'jv', 'js', 'ti', 'wp')
# 
# # We're using a for loop because I'm done copy-pasting
# for(col in cont_names){
#     # First we create new column names for centered and standardized data.
#     cent_name = paste0(col, "_cent")
#     std_name  = paste0(col, "_std")
#     
#     # Now we center
#     raw_dat[[cent_name]] <- raw_dat[[col]] - mean( raw_dat[[col]], na.rm = TRUE )
#     
#     # And we standardize using the scale function
#     raw_dat[[std_name]] <- scale( raw_dat[[col]], center = TRUE, scale = TRUE )[,1]
#     
# }

```

### Descriptive Statistics - Raw Data

This section will look at base descriptive statistics of the raw data to help identify data anomalies and check   
normality of predictor variables (break length - minutes)

```{r descriptive_stats_raw}

# # We'll need to check both univariate normality and multi-variate normality. 
# my_descr = jmv::descriptives( this_dat,
#                               vars = c('fa', 'ppr', 'agg', 'p_mod_f'),
#                               hist = TRUE,
#                               dens = TRUE,
#                               qq = TRUE,
#                               sd = TRUE,
#                               variance = TRUE,
#                               se = TRUE,
#                               skew = TRUE,
#                               kurt = TRUE,
#                               missing = TRUE
#                             )
# print(my_descr)

```

### Correlation Plots - Raw Data

Visualize the covariance matrix to understand correlation between break length and employee productivity


```{r correlation_plots_raw}

# # We look at correlations for both the centered and uncentered data.... turns out it doesn't matter
# 
# # Uncentered correlations
# m1_subset = this_dat[ c('agg', 'fa', 'ppr') ]
# agg_cor_m1 <- stats::cor( m1_subset )
# corrplot( agg_cor_m1,
#           method="color",
#           type = "full",
#           addCoef.col = "black",
#           col = rb_colmap,
#           tl.col = font_color )
# 
# # Centered correlations.
# m2_subset = this_dat[ c('agg', 'fa_cent', 'ppr_cent') ]
# agg_cor_m1 <- stats::cor( m2_subset )
# corrplot( agg_cor_m1,
#           method="color",
#           type = "full",
#           addCoef.col = "black",
#           col = rb_colmap,
#           tl.col = font_color )
# 
# # Print correlation tables (annoying that we have to use two different correlation functions, 1 for plotting and
# # 1 for tables, but oh well)
# agg_cor_tab_m2 <- jmv::corrMatrix(m2_subset, flag = TRUE)
# print( agg_cor_tab_m2 )

```

### Scatterplots of Variables

```{r scatter_plots}
# 
# # Scatterplot 1: Aggression vs. Family Adversity  (uncentered)
# agg_scatter_faunc <- ggplot(this_dat, aes(agg, fa) )
# 
# agg_scatter_faunc +
#     geom_point() +
#     geom_smooth(method = "lm", colour = "Red") +
#     ggtitle("Childhood Aggression as a Function of Family Adversity") +
#     labs(y = "Childhood Aggression (1-20)", x = "Family Adversity (1-20)") +
#     my_gg_theme
# 
# 
# # Scatterplot 2: Aggression vs. Positive Peer Support  (uncentered)
# agg_scatter_ppruc <- ggplot(this_dat, aes(agg, ppr) )
# 
# agg_scatter_ppruc +
#     geom_point() +
#     geom_smooth(method = "lm", colour = "Red") +
#     ggtitle("Childhood Aggression as a Function of Positve Peer Relationships") +
#     labs(y = "Childhood Aggression (1-20)", x = "Positive Peer Relationships (1-20)") +
#     my_gg_theme

# Make sure you plot OV as fncn of both PV and Mediator.

# Make sure you plot Mediator as function of PV

```

### Build Simple Linear Models (lm)

```{r linear_model_definition}

# # We create a simple linear model using the two main effect predictors (FA and PPR) w/o accounting for moderation
# # to aid in simple data assumption checks later on (homoscedasticity and multi-variate normality.)
#  
# # Aggression regressed onto family adversity and positive peer support as main effect predictors.
# agg_simp_mod_uc <- lm( agg ~ fa + ppr, data = this_dat)
# 
# # Model performance checks for all models
# performance::check_model(agg_simp_mod_uc)
# 
# # We'll create a simple model that includes the moderation term as well
# # NOTE: We're using uncentered data here:
# agg_me_w_mod_model_uc <- lm(agg ~ fa + ppr + p_mod_f, data = this_dat)
# # Notice funny grouping when we define model as above. Spot checked these alternative models and it's not clear which is  
# # better.
# # agg_me_w_mod_model_uc <- lm(agg ~ p_mod_f, data = this_dat)
# # agg_me_w_mod_model_uc <- lm(agg ~ fa_cent + ppr_cent + p_mod_f_cent, data = this_dat)

# Unstandardized linear model definition

# Unstandardized Path a

# Unstandardized Paths b + c'


# Standardized linear model definition

# Standardized Path a

# Standardized Path b + c'


```


### Residuals Plots
```{r residuals_figures}

# # Check Residuals plot (Heteroscedasticity)
# # Fitted values vs. residuals to examine homoscedasticity
# # NOTE use of .resid to plot residuals
# 
# 
# # Main Effects: agg ~ fa + ppr
# agg_resid_me_fig = ggplot( agg_simp_mod_uc, aes(.fitted, .resid) )
# 
# agg_resid_me_fig +
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Childhood Aggression Levels (1-20)") +
#     ylab("Aggression Residuals (1 - 20)") +
#     ggtitle("Main Effects Childhood Aggression Residual vs. Fitted Plot") +
#     my_gg_theme
# 
# # I also want to see a residuals plot in multiples of SD of productivity to help spot outliers
# agg_resid_me_sd_fig = ggplot( agg_simp_mod_uc,
#                               aes(.fitted , .resid / my_descr$descriptives$asDF$`agg[sd]` )
#                             )
# 
# agg_resid_me_sd_fig +
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Childhood Aggression Levels (1-20)") +
#     ylab(expression( "Residuals - Standardized (Multiples of " * sigma * ")") )  +
#     ggtitle("Main Effects Childhood Aggression Residual vs. Fitted Plot") +
#     my_gg_theme
# 
# # Create Residuals plot for Fitted values with Moderation Accounted for
# 
# # Moderation Effects: agg ~ fa + ppr + p_mod_f
# agg_resid_mod_fig = ggplot( agg_me_w_mod_model_uc, aes(.fitted, .resid) )
# 
# agg_resid_mod_fig +
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Childhood Aggression Levels (1-20)") +
#     ylab("Aggression Residuals (1 - 20)") +
#     ggtitle("Main + Moderation Effects Childhood Aggression Residual vs. Fitted Plot") +
#     my_gg_theme
# 
# # I also want to see a residuals plot in multiples of SD of productivity to help spot outliers
# agg_resid_mod_sd_fig = ggplot( agg_me_w_mod_model_uc,
#                               aes(.fitted , .resid / my_descr$descriptives$asDF$`agg[sd]` )
#                             )
# 
# agg_resid_mod_sd_fig +
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Childhood Aggression Levels (1-20)") +
#     ylab(expression( "Residuals - Standardized (Multiples of " * sigma * ")") )  +
#     ggtitle("Main + Moderation Childhood Aggression Residual vs. Fitted Plot") +
#     my_gg_theme

```


### Homoscedasticity Checks
```{r homoscedasticity_checks}

# # Run a Breusch Pagan Test of homoscedasticity for both models, for both reference grad values
# 
# cat( paste("  ", "---- Breusch-Pagan Main Effects ----", " ", sep = "\n") )
# car::ncvTest(agg_simp_mod_uc)
# 
# cat( paste("  ", "---- Breusch-Pagan Main + Moderation Effects ----", " ", sep = "\n") )
# car::ncvTest(agg_me_w_mod_model_uc)


```


### Multi-Variate Normality

```{r multivar_norm}


# # Code below manually produces QQ Plot for better alignment with general plot styles
# ggplot(agg_simp_mod_uc, 
#          aes( 
#                qqnorm( .stdresid,
#                        xlab = "", ylab = "", 
#                        conf.level = 0.945, 
#                        conf.args = list(col = "lightgrey", exact = TRUE) 
#                       )[[1]],
#                .stdresid ) 
#        ) + 
#     geom_point(na.rm = TRUE) +
#     xlab("Theoretical Quantiles") + 
#     ylab("Standardized Residuals") +
#     ggtitle("Normal Q-Q of Main Effects Model") + 
#     my_gg_theme
# 
# # Henze-Zirkler test of multivariate normality
# # Columns 2-4 are Aggression, Family Adversity, and Positive Peer Support respectively.
# HZ.test(this_dat[2:4])


```






### Assumptions, Figures, and Plots - Raw Data

Descriptives section already checked normality so here we need to focus on linearity and homoscedasticity. We're  
going to center the data outright because I don't want to run everything multiple times.

```{r assumptions_and_figures_raw}

# SAMPLE CODE
# # Centering the data
# breaks_dat$length_centered <- breaks_dat$length - mean(breaks_dat$length)
# 
# 
# # Check Scatterplot of Centered data: Break Length is PV, Productivity is OV
# breaks_raw_scatter <- ggplot(breaks_dat, aes(length, product) )
# 
# breaks_raw_scatter + 
#     geom_point() + 
#     geom_smooth(method = "lm", colour = "Red") + 
#     ggtitle("Break Length Relation to Employee Productivity") + 
#     labs(x = "Break Length (m)", y = "Employee Productivity (0-100)") +
#     theme_minimal() +
#     theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
#            axis.title.x = element_text(color = font_color),
#            axis.title.y = element_text(color = font_color),
#            axis.text.x = element_text(color = font_color),
#            axis.text.y = element_text(color = font_color),
#            legend.title = element_text(color = font_color),
#            legend.text = element_text(color = font_color),
#            panel.grid.minor = element_line(color = grid_color_minor),
#            panel.grid.major = element_line(color = grid_color_major),
#            panel.background = element_rect(fill = back_color, color = font_color)
#          )
# 
# breaks_cent_scatter <- ggplot(breaks_dat, aes(length_centered, product) )
# 
# breaks_cent_scatter + 
#     geom_point() + 
#     geom_smooth(method = "lm", colour = "Red") + 
#     ggtitle("Break Length Relation to Employee Productivity") + 
#     labs(x = "Break Length - Centered (m)", y = "Employee Productivity (0-100)") +
#     theme_minimal() +
#     theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
#            axis.title.x = element_text(color = font_color),
#            axis.title.y = element_text(color = font_color),
#            axis.text.x = element_text(color = font_color),
#            axis.text.y = element_text(color = font_color),
#            legend.title = element_text(color = font_color),
#            legend.text = element_text(color = font_color),
#            panel.grid.minor = element_line(color = grid_color_minor),
#            panel.grid.major = element_line(color = grid_color_major),
#            panel.background = element_rect(fill = back_color, color = font_color)
#          )
# 
# 
# # Check Residuals plot (Heteroscedasticity)
# # To compute residuals we need to define the model as productivity regressed onto break length in a linear fashion
# breaks_model_lin <- lm(product ~ length, data = breaks_dat)
# 
# # Fitted values vs. residuals to examine homoscedasticity
# # NOTE use of .resid to plot residuals
# breaks_resid_fig = ggplot( breaks_model_lin, aes(.fitted, .resid) )
# 
# breaks_resid_fig + 
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Productivity Values (0 - 100)") +
#     ylab("Productivity Residuals (0 - 100)") +
#     ggtitle("Residual vs. Fitted Plot") +
#     theme_minimal() +
#     theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
#            axis.title.x = element_text(color = font_color),
#            axis.title.y = element_text(color = font_color),
#            axis.text.x = element_text(color = font_color),
#            axis.text.y = element_text(color = font_color),
#            legend.title = element_text(color = font_color),
#            legend.text = element_text(color = font_color),
#            panel.grid.minor = element_line(color = grid_color_minor),
#            panel.grid.major = element_line(color = grid_color_major),
#            panel.background = element_rect(fill = back_color, color = font_color)
#          )
# 
# # I also want to see a residuals plot in multiples of SD of productivity to help spot outliers
# breaks_resid_sd_fig = ggplot( breaks_model_lin, aes(.fitted , .resid / breaks_descr$descriptives$asDF$`product[sd]` ) )
# 
# breaks_resid_sd_fig + 
#     geom_point(col = font_color) +
#     geom_hline(yintercept=0, col="green3", linetype="dashed") +
#     xlab("Fitted Productivity Values") +
#     ylab(expression( "Residuals - Standardized (Multiples of " * sigma * ")") )  +
#     ggtitle("Productivity Residual vs. Fitted Plot") +
#     theme_minimal() +
#     theme( plot.title = element_text(size = 12, face = "italic", color = font_color),
#            axis.title.x = element_text(color = font_color),
#            axis.title.y = element_text(color = font_color),
#            axis.text.x = element_text(color = font_color),
#            axis.text.y = element_text(color = font_color),
#            legend.title = element_text(color = font_color),
#            legend.text = element_text(color = font_color),
#            panel.grid.minor = element_line(color = grid_color_minor),
#            panel.grid.major = element_line(color = grid_color_major),
#            panel.background = element_rect(fill = back_color, color = font_color)
#          )  
# 
# # Run a Breusch Pagan Test of homoscedasticity
# car::ncvTest(breaks_model_lin)
```

### Data Cleaning - OPTIONAL
If there are data issues that need to be adjusted, clean the data here.

``` {r data_cleaning_raw}

```

### Construct Mediation Models

We need to perform multiple mediation analysis methods, including B&K's OG method, that same supplemented with Sobel's  
test, and bootstrapping our best answer. For bootstrapping, we'll want both standardized and unstandardized coefficient  
outputs which means we'll need to define our linear regression models with both standardized data and unstandardized   
data.

#### Baron and Kenny

Here we use B&K's method to evaluate the impact of mediation


```{r baron_and_kenny_method}

# SAMPLE CODE - SIMPLE REGRESSION
# #simple regression looking at self-efficacy (centered) as a predictor of desire to lead in a group (e.g. self-efficacy (centered) regressed on desire to lead)
# breaks_model_lin_reg <- linReg( data = breaks_dat, 
#                                 dep = 'product', 
#                                 covs = c('length_centered'), 
#                                 blocks = list( c( 'length_centered') ), 
#                                 modelTest = TRUE, 
#                                 stdEst = TRUE,
#                                 ci = TRUE)
# breaks_model_lin_reg

# Model 1: Evaluate Total Effect (Path c), regress OV onto PV

# Model 2: Evaluate Path a (regress mediator onto PV)

# Model 3: Evaluate Path b and c'  regress OV onto Mediator and PV

```

#### Sobel's Test

Now we need to perform the Null Hypothesis test to evaluate if the a+b effects are significantly discernable from 0  

```{r sobel_test}
# Do Sobel Things


```

#### Bootstrap's Bootstraps - Unstandardized Bootstraps
```{r unstandardized_bootstrap}
# mediation::mediate()


```



#### Bootstrap me Baby, One More Time - Standardized Bootstraps

```{r standardized_bootstrap}
# mediation::mediate()

```


### Build Simple Regression Model

Centered data is already saved from scatter plots above (shift the y-intercept to the mean of the dataset).  
Now we can build the regression model.  

```{r simple_regression}

# SAMPLE CODE
# #simple regression looking at self-efficacy (centered) as a predictor of desire to lead in a group (e.g. self-efficacy (centered) regressed on desire to lead)
# breaks_model_lin_reg <- linReg( data = breaks_dat, 
#                                 dep = 'product', 
#                                 covs = c('length_centered'), 
#                                 blocks = list( c( 'length_centered') ), 
#                                 modelTest = TRUE, 
#                                 stdEst = TRUE,
#                                 ci = TRUE)
# breaks_model_lin_reg


```


